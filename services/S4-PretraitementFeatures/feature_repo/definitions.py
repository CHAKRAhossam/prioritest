# This is an example feature definition file

from datetime import timedelta
from feast import Entity, FeatureService, FeatureView, Field, FileSource, PushSource, RequestSource
from feast.types import Float32, Int64, String

# Define an entity for the commit
commit = Entity(name="commit", join_keys=["commit_id"])

# Define the source of the data
# Pointing to the features.csv generated by the pipeline
# Note: In a real scenario, this might point to a parquet file or a data warehouse table
feature_source = FileSource(
    name="commit_features_source",
    path="../data/processed/features.parquet",  # Path relative to feature_repo
    timestamp_field="commit_date",
)

# Define the Feature View
commit_features_view = FeatureView(
    name="commit_features",
    entities=[commit],
    ttl=timedelta(days=365),
    schema=[
        Field(name="lines_modified", dtype=Float32),
        Field(name="complexity", dtype=Float32),
        Field(name="churn", dtype=Int64),
        Field(name="num_authors", dtype=Int64),
        Field(name="bug_fix_proximity", dtype=Int64),
        # Encoded features (examples, assuming OneHotEncoder output format)
        # In a real dynamic scenario, you might generate this list programmatically
        # or use a different storage format (e.g. Parquet) that preserves schema better.
        # For this example, we'll include a few common ones if they exist, 
        # but since OneHotEncoder generates dynamic names, we'll stick to the stable ones above for the demo.
    ],
    online=True,
    source=feature_source,
    tags={"team": "ml-ops"},
)
