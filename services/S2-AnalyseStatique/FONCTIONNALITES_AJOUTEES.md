# Fonctionnalit√©s Ajout√©es au Service S2 - AnalyseStatique

## üìã R√©sum√©

Ce document liste toutes les fonctionnalit√©s ajout√©es pour compl√©ter le Service 2 selon le cahier des charges.

## ‚úÖ Fonctionnalit√©s Impl√©ment√©es

### 1. Int√©gration Kafka ‚úÖ

- **Consumer Kafka** : `CommitEventConsumer` qui consomme les messages du topic `repository.commits`
- **Producer Kafka** : `KafkaService` qui publie les m√©triques vers le topic `code.metrics`
- **Configuration Kafka** : `KafkaConfig` avec support pour producers et consumers
- **DTOs** : 
  - `CommitEvent` : Structure pour les messages entrants depuis `repository.commits`
  - `CodeMetricsEvent` : Structure pour les messages sortants vers `code.metrics`

### 2. Int√©gration Git (JGit) ‚úÖ

- **GitService** : Service pour cloner des d√©p√¥ts Git et checkout un commit sp√©cifique
- Support pour :
  - Clonage de d√©p√¥ts Git
  - Checkout d'un commit sp√©cifique
  - Gestion des r√©pertoires temporaires
  - Nettoyage automatique

### 3. Calcul des M√©triques Globales ‚úÖ

- **GlobalMetricsService** : Service pour calculer les m√©triques n√©cessitant une vue globale du projet
- **NOC (Number of Children)** : Calcul du nombre d'enfants pour chaque classe (n√©cessite analyse de l'h√©ritage)
- **In/Out Degree** : Calcul des degr√©s d'entr√©e et de sortie dans le graphe de d√©pendances avec JGraphT
- Utilisation de **JGraphT** pour construire et analyser le graphe de d√©pendances

### 4. Int√©gration Feast Feature Store ‚úÖ

- **FeastService** : Service pour publier les m√©triques vers Feast Feature Store
- Format des donn√©es conforme au sch√©ma Feast
- Publication asynchrone via WebClient (reactive)

### 5. Configuration PostgreSQL/TimescaleDB ‚úÖ

- Configuration dans `application.properties` pour PostgreSQL
- Support TimescaleDB (compatible PostgreSQL)
- Configuration JPA/Hibernate pour la persistance

### 6. Am√©lioration du MetricsService ‚úÖ

- Nouvelle m√©thode `processCommitEvent()` pour traiter les √©v√©nements depuis Kafka
- Int√©gration compl√®te du pipeline :
  1. R√©ception √©v√©nement commit depuis Kafka
  2. Clonage du d√©p√¥t au commit donn√©
  3. Analyse des fichiers modifi√©s
  4. Calcul des m√©triques (CK, d√©pendances, smells)
  5. Calcul des m√©triques globales (NOC, in/out degree)
  6. Publication vers Kafka et Feast

### 7. Configuration et Infrastructure ‚úÖ

- **KafkaConfig** : Configuration compl√®te pour Kafka (producers/consumers)
- **WebClientConfig** : Configuration pour WebClient (Feast)
- **JacksonConfig** : Configuration pour ObjectMapper (JSON)
- **application.properties** : Toutes les configurations n√©cessaires

## üì¶ D√©pendances Ajout√©es

Les d√©pendances suivantes ont √©t√© ajout√©es au `pom.xml` :

- `spring-kafka` : Int√©gration Kafka
- `org.jgrapht:jgrapht-core` : Graphe de d√©pendances
- `org.eclipse.jgit:org.eclipse.jgit` : Op√©rations Git
- `spring-boot-starter-webflux` : Client HTTP r√©actif (Feast)
- `postgresql` : Driver PostgreSQL
- `jackson-datatype-jsr310` : Support dates/temps

## üîÑ Flux de Traitement

```
Kafka (repository.commits)
    ‚Üì
CommitEventConsumer
    ‚Üì
MetricsService.processCommitEvent()
    ‚Üì
GitService.cloneAndCheckout()
    ‚Üì
Analyse fichiers modifi√©s
    ‚Üì
Extraction m√©triques (CK, d√©pendances, smells)
    ‚Üì
GlobalMetricsService (NOC, in/out degree)
    ‚Üì
Publication vers Kafka (code.metrics) + Feast
```

## ‚ö†Ô∏è Fonctionnalit√©s Restantes (Optionnelles)

### 1. Support Python (radon) ‚è≥

- Actuellement, seul Java est support√©
- Pour ajouter le support Python, il faudrait :
  - Cr√©er un service Python s√©par√© (recommand√©)
  - Ou int√©grer radon via Jython (complexe)
  - Ou utiliser un appel syst√®me vers un script Python

### 2. Normalisation par Module/Langage ‚è≥

- La normalisation n'est pas encore impl√©ment√©e
- Pourrait √™tre ajout√©e dans `GlobalMetricsService` ou un service d√©di√©

### 3. Am√©lioration du calcul NOC ‚è≥

- Le calcul actuel de NOC est simplifi√©
- Pour une version compl√®te, il faudrait parser l'h√©ritage depuis les fichiers sources

## üöÄ Utilisation

### D√©marrer le service

1. D√©marrer les services requis (Kafka, PostgreSQL, Feast) via docker-compose
2. Configurer `application.properties` avec les bonnes URLs
3. Lancer l'application Spring Boot

### Tester avec Kafka

Envoyer un message au topic `repository.commits` :

```json
{
  "event_id": "evt_123",
  "repository_id": "repo_12345",
  "commit_sha": "abc123",
  "files_changed": [
    {
      "path": "src/UserService.java",
      "status": "modified"
    }
  ]
}
```

Le service va automatiquement :
1. Cloner le d√©p√¥t
2. Analyser les fichiers
3. Publier les m√©triques vers `code.metrics` et Feast

## üìù Notes

- Le service assume que `repository_id` correspond √† un d√©p√¥t GitHub (format `owner/repo`)
- Pour d'autres sources Git, il faudrait un service de mapping `repository_id` ‚Üí URL Git
- Le nettoyage des d√©p√¥ts clon√©s est optionnel (peut √™tre gard√© pour cache)

